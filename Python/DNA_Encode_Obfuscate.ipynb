{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a677c11",
   "metadata": {},
   "source": [
    "# Encode and Obbfuscate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682c69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import Counter\n",
    "import numpy as np  \n",
    "\n",
    "def build_huffman_tree_Optimized(text, base=2):\n",
    "    \"\"\"\n",
    "    Build a Huffman tree for different base encodings, translating paths to DNA bases\n",
    "    or corresponding symbols immediately to avoid ambiguity in path representation.\n",
    "    \"\"\"\n",
    "    assert base >= 2 and base <= 22 # Ensure valid base\n",
    "\n",
    "    # Mapping for DNA bases and extended symbols for bases 11 and 12\n",
    "    base_to_dna ={0:'W', 1:'S', 2:'M', 3:'K', 4:'Y', 5:'R', 6:'T', 7:'C', 8:'G', 9:'A'}\n",
    "    # Count frequency of each character in the text\n",
    "    frequency = Counter(text)\n",
    "    N=1\n",
    "    while (base-1)*N+1 < len(frequency):\n",
    "       N+=1\n",
    "    add_dum=(base-1)*N+1-len(frequency) \n",
    "    # add add_dum dummy characters to the frequency, with 0 frequency\n",
    "    for i in range(add_dum):\n",
    "        dummy_char =\"X\"+str(i)\n",
    "        frequency[dummy_char] = 0\n",
    "    \n",
    "    # Initialize priority queue with frequency count\n",
    "    heap = [[weight, [symbol, \"\"]] for symbol, weight in frequency.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        combined_weight = 0\n",
    "        new_node = []\n",
    "        \n",
    "        # Combine up to 'base' nodes from the heap\n",
    "        for i in range(min(base, len(heap))):\n",
    "            \n",
    "            node = heapq.heappop(heap)\n",
    "            \n",
    "            combined_weight += node[0]\n",
    "         \n",
    "                \n",
    "\n",
    "            # Append a unique path digit for each combined node, directly translating to DNA bases\n",
    "            for symbol, path in node[1:]:\n",
    "    \n",
    "                new_path = base_to_dna[i] + path  # Translate immediately to DNA base\n",
    "                new_node.append([symbol, new_path])\n",
    "                \n",
    "            \n",
    "        heapq.heappush(heap, [combined_weight] + new_node)\n",
    "    return sorted(heapq.heappop(heap)[1:], key=lambda p: (len(p[-1]), p))\n",
    "\n",
    "\n",
    "\n",
    "def huffman_encoding(text, huffman_tree):\n",
    "    \"\"\"\n",
    "    Encode the text using the Huffman tree, translating the path steps directly to encoded characters.\n",
    "    \"\"\"\n",
    "    # Map symbols to their codes from the Huffman tree\n",
    "    huffman_dict = {symbol: code for symbol, code in huffman_tree}\n",
    "    # Encode the text using the Huffman codes\n",
    "    encoded_text = ''.join(huffman_dict[char] for char in text)\n",
    "    \n",
    "    return encoded_text\n",
    "\n",
    "def huffman_decoding(encoded_text, huffman_tree):\n",
    "    \"\"\"\n",
    "    Decode the text using the Huffman tree, translating encoded characters back to the original symbols.\n",
    "    \"\"\"\n",
    "    # Reverse the Huffman dictionary to map codes to symbols\n",
    "    huffman_dict = {code: symbol for symbol, code in huffman_tree}\n",
    "    \n",
    "    decoded_text = \"\"\n",
    "    current_code = \"\"\n",
    "    for digit in encoded_text:\n",
    "        current_code += digit\n",
    "        if current_code in huffman_dict:\n",
    "            decoded_text += huffman_dict[current_code]\n",
    "            current_code = \"\"  # Reset for the next symbol\n",
    "    \n",
    "    return decoded_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a697c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def decompsiotion(sequence):\n",
    "    combined_bases = {'R': ['A', 'G'], 'Y': ['C', 'T'], 'K': ['G', 'T'], 'M': ['A', 'C'], 'S': ['C', 'G'], 'W': ['A', 'T']}\n",
    "   # Replace combined bases with proper bases\n",
    "    expanded_sequence_1= ''\n",
    "    expanded_sequence_2= ''\n",
    "    for base in sequence:\n",
    "        if base in combined_bases:\n",
    "            choice_1 = random.choice(combined_bases[base])\n",
    "            expanded_sequence_1 += choice_1\n",
    "\n",
    "            # For sequence_2, choose the other base\n",
    "            remaining_choices = [b for b in combined_bases[base] if b != choice_1]\n",
    "            choice_2 = remaining_choices[0]  # Since there is always exactly one other choice\n",
    "            expanded_sequence_2 += choice_2\n",
    "        else:\n",
    "            expanded_sequence_1 += base\n",
    "            expanded_sequence_2 += base\n",
    "    return expanded_sequence_1, expanded_sequence_2\n",
    "    \n",
    "\n",
    "\n",
    "def simulate_reads(sequence, error_rate, num_reads):\n",
    "  \n",
    "  # Set the seed to the current time\n",
    "\n",
    "  results = []\n",
    "\n",
    "  # Replace combined bases with proper bases\n",
    "  for num in range(num_reads):\n",
    "  #simulate erros\n",
    "    read = ''\n",
    "    for base in sequence:\n",
    "      if random.random() < error_rate:\n",
    "        read += np.random.choice(['A', 'C', 'G', 'T'])\n",
    "      else:\n",
    "        read += base\n",
    "\n",
    "    results.append(read)\n",
    "  return results\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "def read_fasta(filename):\n",
    "    \"\"\"Reads sequences from a FASTA file.\"\"\"\n",
    "    sequences = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('>'):\n",
    "                sequences.append(line.strip())\n",
    "    return sequences\n",
    "\n",
    "def calculate_base_frequencies(sequences):\n",
    "    \"\"\"Calculates the frequency of each base at every position.\"\"\"\n",
    "    sequence_length = len(sequences[0])\n",
    "    base_counts = [Counter() for _ in range(sequence_length)]\n",
    "\n",
    "    for seq in sequences:\n",
    "        for i, base in enumerate(seq):\n",
    "            base_counts[i][base] += 1\n",
    "\n",
    "    base_frequencies = []\n",
    "    for counts in base_counts:\n",
    "        total = sum(counts.values())\n",
    "        frequencies = {base: count / total for base, count in counts.items()}\n",
    "        base_frequencies.append(frequencies)\n",
    "    return base_frequencies\n",
    "\n",
    "def apply_cutoff(base_frequencies, cutoff=0.05):\n",
    "    \"\"\"Applies a frequency cutoff to base frequencies.\"\"\"\n",
    "    return [{base: freq for base, freq in frequencies.items() if freq >= cutoff} for frequencies in base_frequencies]\n",
    "\n",
    "def replace_with_combined_bases(frequencies):\n",
    "    \"\"\"Replaces bases with IUPAC combined bases according to the frequencies.\"\"\"\n",
    "    iupac_codes = {\n",
    "        frozenset(['A', 'G']): 'R', frozenset(['C', 'T']): 'Y',\n",
    "        frozenset(['G', 'T']): 'K', frozenset(['A', 'C']): 'M',\n",
    "        frozenset(['G', 'C']): 'S', frozenset(['A', 'T']): 'W',\n",
    "        frozenset(['A']): 'A', frozenset(['C']): 'C',\n",
    "        frozenset(['G']): 'G', frozenset(['T']): 'T',\n",
    "    }\n",
    "\n",
    "    consensus_sequence = ''\n",
    "    for pos_freq in frequencies:\n",
    "        significant_bases = frozenset(pos_freq.keys())\n",
    "        consensus_sequence += iupac_codes.get(significant_bases, 'A')  # 'N' if no significant bases or combination not in table\n",
    "\n",
    "    return consensus_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91983083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def obfuscation_data_generate(Data):\n",
    "    combined_bases = {'R': ['A', 'G'], 'Y': ['C', 'T'], 'K': ['G', 'T'], 'M': ['A', 'C'], 'S': ['C', 'G'], 'W': ['A', 'T']}\n",
    "    obfuscation=[]\n",
    "    for i in range(len(Data)):\n",
    "        if Data[i] in ['A','T','C','G']:\n",
    "            # replace the base different from the original base\n",
    "            obfuscation.append(np.random.choice([base for base in ['A','T','C','G'] if base!=Data[i]]))\n",
    "        else:\n",
    "          # add the the base the same as original base\n",
    "            obfuscation.append(Data[i])\n",
    "    obfuscation=''.join(obfuscation)\n",
    "    return obfuscation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a577769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decryption  (consensus_sequence,obfuscation_seqs):\n",
    "    combined_bases = {'R': ['A', 'G'], 'Y': ['C', 'T'], 'K': ['G', 'T'], 'M': ['A', 'C'], 'S': ['C', 'G'], 'W': ['A', 'T']}\n",
    "    decrypted=''\n",
    "    for i in range(len(consensus_sequence)):\n",
    "        if consensus_sequence[i] == obfuscation_seqs[i]:\n",
    "            decrypted+=consensus_sequence[i]\n",
    "        else:\n",
    "            choice=[b for b in combined_bases[consensus_sequence[i]] if b != obfuscation_seqs[i]]\n",
    "            decrypted+=choice[0]\n",
    "    return decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3eca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text=\"\"\"When I find myself in times of trouble\n",
    "Mother Mary comes to me\n",
    "Speaking words of wisdom\n",
    "Let it be\n",
    "And in my hour of darkness\n",
    "She is standing right in front of me\n",
    "Speaking words of wisdom\n",
    "Let it be\n",
    "Let it be, let it be\n",
    "Let it be, let it be\n",
    "Whisper words of wisdom\n",
    "Let it be\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2046eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "376\n",
      "TMAKCSGTRGGATYSAGGACTGMCAWATGYSGRYACCMGKATGRAAKTKARAWCWTSKRAKCAAGTSAMAATGGTRAKACCMGRKGACCWTYTCCAMTTYSTAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCWTRCSAGGYSGACTGGAKKTKAAGKATGAGAMAATTSCMMWTYAKCGYMGMRAMSAGYSTAGAAYTAAKRGYSGATAAKSRGKATGACCWTYTCCAMTTYSTAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCWASCRGYRGARCTWGAWCRGYRGARCWASCRGYRGARCTWGAWCRGYRGARCWTMAKYMTCCAAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCW\n"
     ]
    }
   ],
   "source": [
    "huffman_tree = build_huffman_tree_Optimized(example_text, base=10)\n",
    "encoded_text=huffman_encoding(example_text, huffman_tree)\n",
    "print(len(example_text))\n",
    "print(len(encoded_text))\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5761af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obfu_1=\"GACGACTCGACCATCCACTGGTATCTTGACCCACGGTCAGGGAGGCGAGTGTTATGGTGCTAGCCGGCAGGGCACAGTCATCTAGCGATTCCATTGCCCCCCGCTTGTTGCAATCAACTTAGCGCGTGCAATTGACATTAGGGGTTTCCGACTTTGTGTGTTTGCATATCCTAACACATATGGATCCCCATACTCTCGCCCTCGCCGGATGTTCCCTCGTGTACTGGAATCGATCCACGCCCCCTTGTACAGCAAGCTCGATTAACGAAATACCATTGCGAATGTGGAGTTGTTATCATCGGAGCTGCCGTCAACATCAAATTATTGTAGACGTCATATTAGTTTTTTCAGCGCTCTCTAGGAATCAACTAAGGAA\"\n",
    "obfu_2=\"GCCTAGTCAACCACGCACTGGTCTCATGATGCGTGGTAATGGAAGCTATTATAAAGCGACGAGCCGCCCGGGCACGGGCATATGTCGATACTATTGACCTGCGCTCTTTGCCAGCAACCCCGCTCGAGGAGTCAACGTAAAGCGTTCGCGACTTTTGGGGTTGGCATATACTAAGAACAACGTATTACAGTCGTCCGGCCCTTGCCTAACCTTCCCGGATTTACTGGTACCGATACATCCCCCTGTGTAAATCAAGTCAGAGTATCCAGACGCCGTAGGGGACATGAAGATGATGTTGTCAGTGGTACTATCGACTTCTAGTCGTTATTGCCTCAATATTAGCGTTTTAATCGCTTCATATGATTGAGCCGAGAAT\"\n",
    "encode_1=\"TAATCCGTGGGATCCAGGACTGACAAATGCCGGTACCCGTATGAAAGTGAAATCATGTAAGCAAGTGAAAATGGTAAGACCCGATGACCATTTCCAATTTCTAGACTAAAGAGGATGACTAAGTACAAGCAGCGGAGCATGCCAGGCGGACTGGATTTTAAGGATGAGACAATTGCCCTTTAGCGCCGAGAACAGTCTAGAATTAATGGTCGATAAGCAGTATGACCATTTCCACTTCCTAGATGAAAGCGTATGACTAAGTACTACCGGTGGAACTACCAGTGGAACTAGAACAGTAGAACTACCAGCGGAACTTGATCAGCAGAGCATAATCCTCCAAGATTAAAGCGGATGACCAAGTACAAGCAGCAGAACT\"\n",
    "encode_2=\"TCAGCGGTAGGATTGAGGACTGCCATATGTGGACACCAGGATGGAATTTAGAACTTCGGATCAAGTCACAATGGTGATACCAGGGGACCTTCTCCACTTCGTAGATGAAAGCGTATGATCCAGGACTACCGGTAGAACTTACGAGGTCGACTGGAGGTGAAGTATGAGAAAATTCCAAATCATCGTAGCAACGAGCGTAGAACTAAGAGCGGATAATGGGGATGACCTTCTCCAATTTGTAGACTAAAGAGGATGATCCAGGACAAGCAGCAGAGCAAGCGGCAGAGCTTGATCGGCGGAGCAAGCGGTAGAGCTAGAACGGTGGAACTTCAGTATCCAAGACGAAAGAGTATGATTCAGGACTACCGGTGGAGCA\"\n",
    "ob_sequnence=\"GMCKASTCRACCAYSCACTGGTMTCWTGAYSCRYGGTMAKGGARGCKAKTRTWAWGSKRCKAGCCGSCMGGGCACRGKCATMTRKCGATWCYATTGMCCYSCGCTYKTTGCMAKCAACYYMGCKCGWGSARTYRACRTWARGSGTTYSCGACTTTKKGKGTTKGCATATMCTAASAMMWAYGKATYMCMRTMSTCYSGCCCTYGCCKRAYSTTCCCKSRTKTACTGGWAYCGATMCAYSCCCCYKTGTAMAKCAAGYYMGAKTAWCSARAYRCCRTWGSGRAYRTGRAGWTGWTRTYRTCRGWGSTRCYRTCRACWTCWARTYRTTRTWGMCKYMATATTAGYKTTTTMAKCGCTYYMTAKGAWTSARCYRAGRAW\"\n",
    "encoded_sequnence=\"TMAKCSGTRGGATYSAGGACTGMCAWATGYSGRYACCMGKATGRAAKTKARAWCWTSKRAKCAAGTSAMAATGGTRAKACCMGRKGACCWTYTCCAMTTYSTAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCWTRCSAGGYSGACTGGAKKTKAAGKATGAGAMAATTSCMMWTYAKCGYMGMRAMSAGYSTAGAAYTAAKRGYSGATAAKSRGKATGACCWTYTCCAMTTYSTAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCWASCRGYRGARCTWGAWCRGYRGARCWASCRGYRGARCTWGAWCRGYRGARCWTMAKYMTCCAAGAYKAAAGMGKATGAYYMAGKACWASCRGYRGARCW\"\n",
    "ref=\"KMMKMSKYRRSMWYSMRSWSKKMYMWWKRYSSRYRSYMRKRKRRRMKWKWRWWMWKSKRMKMRMSKSMMRRKSRYRRKMMYMKRKSRMYWYYWYYRMYYYSYRSWYKWWRSMRKMWRMYYMRSKMSWRSMRKYRRMRYWWRSSRKKYSSRMYKKWKKKKRWKKRYRWRWMMWWWSMMMWWYRKMKYMSMRWMSWSYSKMSMWYKMMKRRYSKWYMMKSRKKWWSWSSWWYYSMWMYWYSYMSMYKWRWRMRKMWRRYYMRRKWMWMSMRRYRSMRYWRSSRRYRKRRMKWKRWYRKYRKMRSWRSYRSYRKMRMYWKMWMRKYRKWRYWKMMKYMWYMWWRRYKWWWKMRKMKSWYYMWRKRMWWSMRSYRRRRMW\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923577fb",
   "metadata": {},
   "source": [
    "# Sequencing analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29293e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap(seq1, seq2):\n",
    "    \"\"\"Find the longest overlap between the end of seq1 and the start of seq2.\"\"\"\n",
    "    overlap_length = 0\n",
    "    for i in range(1, min(len(seq1), len(seq2)) + 1):\n",
    "        if seq1[-i:] == seq2[:i]:\n",
    "            overlap_length = i\n",
    "    return overlap_length\n",
    "\n",
    "def combine_sequences(seq1, seq2):\n",
    "    \"\"\"Combine two sequences by removing the overlapping part from the second sequence.\"\"\"\n",
    "    overlap_length = find_overlap(seq1, seq2)\n",
    "    return seq1 + seq2[overlap_length:]\n",
    "def organize_reads(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        sequences = [line.strip() for line in file.readlines()]\n",
    "    for i in range(len(sequences)):\n",
    "        if ' ' not in sequences[i]:\n",
    "            continue\n",
    "        seq1,seq2=sequences[i].split(' ')\n",
    "        combined_sequence = combine_sequences(seq1, seq2)\n",
    "        sequences[i]=combined_sequence\n",
    "    with open(output_file, 'w') as file:\n",
    "        for sequence in sequences:\n",
    "            file.write(sequence + '\\n')\n",
    "def extract_sequences(input_file, output_file):\n",
    "    target_start = 'GCGATCGC'\n",
    "    target_end = 'GAATTCTGCAGTCGACGGTAC'\n",
    "    \n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            if target_start in line and target_end in line:\n",
    "                parts = line.split(target_start)\n",
    "                if len(parts) > 2:\n",
    "                    # Extract between second occurrence of start and first occurrence of end\n",
    "                    sub_part = target_start.join(parts[2:])  # Get the part after the second GCGATCGC\n",
    "                    seq = sub_part.split(target_end)[0]  # Get up to first GAATTCT...\n",
    "                else:\n",
    "                    # If there's only one occurrence of GCGATCGC\n",
    "                    sub_part = parts[1]  # Get the part after the first GCGATCGC\n",
    "                    seq = sub_part.split(target_end)[0]  # Get up to first GAATTCT...\n",
    "                outfile.write(seq + '\\n')\n",
    "            elif target_start in line:\n",
    "                # Only the start is present\n",
    "                sub_part = line.split(target_start)[1]\n",
    "                seq = sub_part.split(target_end)[0]\n",
    "                outfile.write(seq + '\\n')\n",
    "def extract_lines(input_file, output_file):\n",
    "    lines = []\n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if len(line.strip()) == 376:\n",
    "                lines.append(line)\n",
    "    with open(output_file, 'w') as file:\n",
    "        for line in lines:\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(filename):\n",
    "    \"\"\"Reads sequences from a FASTA file.\"\"\"\n",
    "    sequences = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('>'):\n",
    "                sequences.append(line.strip())\n",
    "    return sequences\n",
    "\n",
    "def calculate_base_frequencies(sequences):\n",
    "    \"\"\"Calculates the frequency of each base at every position.\"\"\"\n",
    "    sequence_length = len(sequences[0])\n",
    "    base_counts = [Counter() for _ in range(sequence_length)]\n",
    "\n",
    "    for seq in sequences:\n",
    "        for i, base in enumerate(seq):\n",
    "            base_counts[i][base] += 1\n",
    "\n",
    "    base_frequencies = []\n",
    "    for counts in base_counts:\n",
    "        total = sum(counts.values())\n",
    "        frequencies = {base: count / total for base, count in counts.items()}\n",
    "        base_frequencies.append(frequencies)\n",
    "    return base_frequencies\n",
    "\n",
    "def apply_cutoff(base_frequencies):\n",
    "    \"\"\"Keeps only the top 2 most frequent bases at each position.\"\"\"\n",
    "    filtered = []\n",
    "    for freq in base_frequencies:\n",
    "        # Sort bases by frequency (descending), keep top 2\n",
    "        top2 = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True)[:2])\n",
    "        filtered.append(top2)\n",
    "    return filtered\n",
    "\n",
    "def replace_with_combined_bases(frequencies):\n",
    "    \"\"\"Replaces bases with IUPAC combined bases according to the frequencies.\"\"\"\n",
    "    iupac_codes = {\n",
    "        frozenset(['A', 'G']): 'R', frozenset(['C', 'T']): 'Y',\n",
    "        frozenset(['G', 'T']): 'K', frozenset(['A', 'C']): 'M',\n",
    "        frozenset(['G', 'C']): 'S', frozenset(['A', 'T']): 'W',\n",
    "        frozenset(['A']): 'A', frozenset(['C']): 'C',\n",
    "        frozenset(['G']): 'G', frozenset(['T']): 'T',\n",
    "    }\n",
    "\n",
    "    consensus_sequence = ''\n",
    "    for pos_freq in frequencies:\n",
    "        significant_bases = frozenset(pos_freq.keys())\n",
    "        consensus_sequence += iupac_codes.get(significant_bases, 'A')  # 'N' if no significant bases or combination not in table\n",
    "\n",
    "    return consensus_sequence\n",
    "def decryption  (consensus_sequence,obfuscation_seqs):\n",
    "    combined_bases = {'R': ['A', 'G'], 'Y': ['C', 'T'], 'K': ['G', 'T'], 'M': ['A', 'C'], 'S': ['C', 'G'], 'W': ['A', 'T']}\n",
    "    decrypted=''\n",
    "    for i in range(len(consensus_sequence)):\n",
    "        if consensus_sequence[i] == obfuscation_seqs[i]:\n",
    "            decrypted+=consensus_sequence[i]\n",
    "        else:\n",
    "            choice=[b for b in combined_bases[consensus_sequence[i]] if b != obfuscation_seqs[i]]\n",
    "            decrypted+=choice[0]\n",
    "    return decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bfff178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f'/home/zzk/work/DNA_storage/30-1089119466/Step1/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step1/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step1/', f)) and f.endswith('.fastq')]\n",
    "for file in files:\n",
    "   os.system(f'awk \\'NR%4 ==2\\' {file} > /home/zzk/work/DNA_storage/30-1089119466//Step2/{file[file.rfind(\"/\")+1:]}')  # Extract the sequences from the fastq files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11535ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P2_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P6_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P3_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P10_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P9_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P5_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P7_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P1_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P8_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P4_R2_001.fastq\n"
     ]
    }
   ],
   "source": [
    "files = [f'/home/zzk/work/DNA_storage/30-1089119466/Step2/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step2/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step2/', f)) and f.find(\"R2\")!=-1]\n",
    "for file in files:\n",
    "    print(file)\n",
    "    os.system(f'awk \\'{{print $0}}\\' {file} | rev | tr \\'ATCGN\\' \\'TAGCN\\' > /home/zzk/work/DNA_storage/30-1089119466/Step3/{file[file.rfind(\"/\")+1:]}')  # reverse complement the R2 sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795594bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P10_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P10_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P3_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P3_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P4_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P4_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P6_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P6_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P5_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P5_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P9_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P9_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P7_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P7_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P1_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P1_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P2_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P2_R2_001.fastq\n",
      "/home/zzk/work/DNA_storage/30-1089119466/Step2/P8_R1_001.fastq /home/zzk/work/DNA_storage/30-1089119466/Step3/P8_R2_001.fastq\n"
     ]
    }
   ],
   "source": [
    "files = [f'/home/zzk/work/DNA_storage/30-1089119466/Step2/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step2/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step2/', f)) and f.find(\"R1\") != -1]\n",
    "for file in files:\n",
    "    file1 = file\n",
    "    file2 = file.replace(\"Step2\",\"Step3\").replace(\"R1\", \"R2\")\n",
    "    print(file1, file2)\n",
    "    os.system(f'paste -d \" \" {file1} {file2} > /home/zzk/work/DNA_storage/30-1089119466/Step4/{os.path.basename(file)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc30e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'/home/zzk/work/DNA_storage/30-1089119466/Step4/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step4/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step4/', f)) and f.endswith('.fastq')]\n",
    "for file in files:\n",
    "    os.system(f'grep -E \\\".*AGCTGGGACCACCTTATATTCCCAG.*GAATTCTGCAGTCGACGGTACC.*\\\" {file} > /home/zzk/work/DNA_storage/30-1089119466/Step5/{file[file.rfind(\"/\")+1:]}')  # filter the sequences with the primers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df480186",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[f'/home/zzk/work/DNA_storage/30-1089119466/Step5/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step5/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step5/', f)) and f.endswith('.fastq')]\n",
    "for file in files:\n",
    "    output=file.replace(\"Step5\",\"Step6\")\n",
    "    organize_reads(file,output) # combine the sequences without the overlapping part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a0549b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[f'/home/zzk/work/DNA_storage/30-1089119466/Step6/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step6/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step6/', f)) and f.endswith('.fastq')]\n",
    "for file in files:\n",
    "    output=file.replace(\"Step6\",\"Step7\")\n",
    "    extract_sequences(file,output) # extract the sequences between the primers\n",
    "files=[f'/home/zzk/work/DNA_storage/30-1089119466/Step7/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step7/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step7/', f)) and f.endswith('.fastq')]\n",
    "for file in files:\n",
    "    output=file.replace(\"Step7\",\"Step8\")\n",
    "    extract_lines(file,output) # extract the sequences with the length of 376, the length which was determined by the obfuscation data                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e8aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P10_R1_001.fastq True\n",
      "P3_R1_001.fastq True\n",
      "P4_R1_001.fastq True\n",
      "P6_R1_001.fastq True\n",
      "P5_R1_001.fastq True\n",
      "P9_R1_001.fastq True\n",
      "P0_R1_001.fastq True\n",
      "P7_R1_001.fastq True\n",
      "P1_R1_001.fastq True\n",
      "P2_R1_001.fastq True\n",
      "P8_R1_001.fastq True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "files=[f'/home/zzk/work/DNA_storage/30-1089119466/Step8/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step8/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step8/', f)) and f.endswith('.fastq')]\n",
    "output_dir='/home/zzk/work/DNA_storage/30-1089119466/base_frequnceies/'\n",
    "for file in files:\n",
    "    sequences = read_fasta(file)\n",
    "    base_frequencies = calculate_base_frequencies(sequences)\n",
    "    # save the base frequencies the first 10 bases into a csv file and each base is one column\n",
    "    csv_path = os.path.join(output_dir, os.path.basename(file).replace('.fastq', '.csv'))\n",
    "    with open(csv_path, mode='w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Base'] + list(range(1, 377)))\n",
    "        for base in ['A', 'C', 'G', 'T']:\n",
    "            frequencies = [freq.get(base, 0) for freq in base_frequencies[:376]]\n",
    "            writer.writerow([base] + frequencies)\n",
    "    filtered_frequencies = apply_cutoff(base_frequencies)\n",
    "    consensus_sequence = replace_with_combined_bases(filtered_frequencies)\n",
    "    print(os.path.basename(file), consensus_sequence == ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f668e4",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "files=[f'/home/zzk/work/DNA_storage/30-1089119466/Step8/{f}' for f in listdir('/home/zzk/work/DNA_storage/30-1089119466/Step8/') if isfile(join('/home/zzk/work/DNA_storage/30-1089119466/Step8/', f)) and f.endswith('.fastq')]\n",
    "number_of_reads=[50,100,500,1000,5000,10000,50000]\n",
    "# sort the files\n",
    "files=sorted(files)\n",
    "for file in files:\n",
    "    i=os.path.basename(file).replace('_R1_001.fastq','')\n",
    "    # shuffle the sequences in the file\n",
    "    sequences=read_fasta(file)\n",
    "    for m in range(0,100):\n",
    "        np.random.shuffle(sequences)\n",
    "        #get the first  number_of_reads[i] sequences and save them to a new file\n",
    "        for n in number_of_reads:\n",
    "            with open(f'/home/zzk/work/DNA_storage/Subsampling/{i}/{n}reads/S{m+1}', 'w') as f:\n",
    "                for seq in sequences[:n]:\n",
    "                    f.write(seq+'\\n')\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
